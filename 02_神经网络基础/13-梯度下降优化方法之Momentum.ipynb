{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🔍 公式解释\n",
    "\n",
    "普通的梯度下降：\n",
    "\n",
    "$$\n",
    "\\theta_{t+1} = \\theta_t - \\eta \\cdot \\nabla L(\\theta_t)\n",
    "$$\n",
    "\n",
    "加入动量后的梯度下降：\n",
    "\n",
    "$$\n",
    "v_{t+1} = \\gamma v_t + \\eta \\cdot \\nabla L(\\theta_t)\n",
    "$$\n",
    "$$\n",
    "\\theta_{t+1} = \\theta_t - v_{t+1}\n",
    "$$\n",
    "\n",
    "其中：\n",
    "\n",
    "- $ \\theta $：模型参数  \n",
    "- $ \\eta $：学习率（learning rate）  \n",
    "- $ \\gamma $：动量系数（通常在 0.9 左右）  \n",
    "- $ v_t $：之前的梯度累积（速度）\n",
    "\n",
    "### 🎯 总结\n",
    "\n",
    "| 方法 | 特点 |\n",
    "|------|------|\n",
    "| 普通梯度下降 | 更新方向由当前梯度决定，容易震荡 |\n",
    "| Momentum | 利用过去梯度，加速收敛，抑制震荡 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.]) tensor([0.9900], requires_grad=True) tensor([0.5000], grad_fn=<DivBackward0>)\n",
      "tensor([0.9900]) tensor([0.9711], requires_grad=True) tensor([0.4901], grad_fn=<DivBackward0>)\n",
      "tensor([0.9711]) tensor([0.9444], requires_grad=True) tensor([0.4715], grad_fn=<DivBackward0>)\n",
      "tensor([0.9444]) tensor([0.9109], requires_grad=True) tensor([0.4459], grad_fn=<DivBackward0>)\n",
      "tensor([0.9109]) tensor([0.8716], requires_grad=True) tensor([0.4149], grad_fn=<DivBackward0>)\n",
      "tensor([0.8716]) tensor([0.8276], requires_grad=True) tensor([0.3799], grad_fn=<DivBackward0>)\n",
      "tensor([0.8276]) tensor([0.7797], requires_grad=True) tensor([0.3425], grad_fn=<DivBackward0>)\n",
      "tensor([0.7797]) tensor([0.7288], requires_grad=True) tensor([0.3039], grad_fn=<DivBackward0>)\n",
      "tensor([0.7288]) tensor([0.6756], requires_grad=True) tensor([0.2655], grad_fn=<DivBackward0>)\n",
      "tensor([0.6756]) tensor([0.6211], requires_grad=True) tensor([0.2282], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "w = torch.tensor(data=[1.0], requires_grad=True, dtype=torch.float32)\n",
    "optimizer = optim.SGD(params=[w], lr=0.01, momentum=0.9)\n",
    "\n",
    "for i in range(10):\n",
    "    loss = (w**2)/2.0\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(w.grad, w, loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
