{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好的，以下是批量归一化（Batch Normalization）的简要总结：\n",
    "\n",
    "### **批量归一化（Batch Normalization，BN）**：\n",
    "\n",
    "**目的**：\n",
    "- 通过对每一层的输入进行归一化处理，缓解梯度消失/爆炸问题，**加速训练**，**提高模型稳定性**，并具有一定的正则化效果。\n",
    "\n",
    "### **工作原理**：\n",
    "1. **计算均值和方差**：\n",
    "   - 对于每一层的输入（某个特征），在当前批次的样本中，计算该特征的**均值**和**方差**。\n",
    "   - 例如，对于第 $ j $ 个特征，计算该特征在批次中的均值 $\\mu_j$ 和方差 $\\sigma_j^2$：\n",
    "     $$\n",
    "     \\mu_j = \\frac{1}{N} \\sum_{i=1}^{N} x_{ij}, \\quad \\sigma_j^2 = \\frac{1}{N} \\sum_{i=1}^{N} (x_{ij} - \\mu_j)^2\n",
    "     $$\n",
    "     其中 $ x_{ij} $ 表示第 $ i $ 个样本的第 $ j $ 个特征，$ N $ 是批次的样本数量。\n",
    "\n",
    "2. **标准化**：\n",
    "   - 对每个特征的输入进行标准化，使其均值为0，方差为1：\n",
    "     $$\n",
    "     \\hat{x}_{ij} = \\frac{x_{ij} - \\mu_j}{\\sqrt{\\sigma_j^2 + \\epsilon}}\n",
    "     $$\n",
    "     其中，$\\epsilon$ 是防止除零错误的小常数。\n",
    "\n",
    "3. **缩放与偏移**：\n",
    "   - 通过引入两个可学习的参数 $\\gamma_j$ 和 $\\beta_j$，对标准化后的值进行**缩放**和平移，使模型可以恢复到最适合的输出：\n",
    "     $$\n",
    "     y_{ij} = \\gamma_j \\hat{x}_{ij} + \\beta_j\n",
    "     $$\n",
    "\n",
    "### **优点**：\n",
    "- **加速训练**：通过归一化输入，减少了层间数据分布的变化，帮助网络更快地收敛。\n",
    "- **提高稳定性**：避免了梯度消失/爆炸问题，使得训练过程更加稳定。\n",
    "- **减小对初始化的敏感性**：批量归一化减轻了网络对权重初始化的依赖。\n",
    "- **具有正则化效果**：虽然主要是为了加速训练，但批量归一化也能起到一定的正则化作用，减少对dropout等方法的依赖。\n",
    "\n",
    "### **注意事项**：\n",
    "- **训练与推理阶段的差异**：训练时，均值和方差基于当前批次计算；推理时，则使用训练过程中累积的全局均值和方差。\n",
    "- **小批量大小**：当批次太小，均值和方差的估计可能不稳定，影响归一化效果。\n",
    "\n",
    "### **总结**：\n",
    "批量归一化通过对每层输入进行标准化，使得神经网络的训练更稳定、收敛更快，同时具有一定的正则化作用。在现代深度学习中，特别是卷积神经网络（CNN）中，批量归一化被广泛应用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after Batch Normalization: tensor([[ 0.9356, -0.8740,  1.5632,  0.6922,  0.3212],\n",
      "        [ 0.8789,  0.3174, -1.0938,  1.1789, -1.7038],\n",
      "        [-1.5013, -0.9424,  0.1114, -0.4994,  0.8295],\n",
      "        [-0.3133,  1.4990, -0.5807, -1.3717,  0.5531]],\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 创建输入数据，假设批次大小为4，每个样本有10个特征\n",
    "input_data = torch.randn(4, 10)\n",
    "\n",
    "# 定义一个全连接层和一个批量归一化层\n",
    "fc = nn.Linear(10, 5)  # 输入10个特征，输出5个特征\n",
    "bn = nn.BatchNorm1d(num_features=5, eps=1e-05, affine=True)  # 批量归一化层，应用于5个特征  affine参数设为True表示weight和bias将被使用\n",
    "\n",
    "# 进行前向传播\n",
    "x = fc(input_data)  # 先通过全连接层\n",
    "x = bn(x)  # 然后通过批量归一化层\n",
    "\n",
    "# 打印输出\n",
    "print(\"Output after Batch Normalization:\", x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([4, 3, 5, 5])\n",
      "Output after Batch Normalization:\n",
      "tensor([[[[ 0.1521, -1.4151, -0.1123, -0.9048, -1.0137],\n",
      "          [ 1.4838,  0.7446, -0.6454,  0.2548, -0.2716],\n",
      "          [-0.4773, -1.1874,  1.8739, -1.3270,  1.4786],\n",
      "          [-0.2357, -0.4830,  0.8439, -0.9579,  1.5019],\n",
      "          [ 0.5290, -0.7307, -0.2575, -1.1911, -0.9277]],\n",
      "\n",
      "         [[ 0.7314,  0.0891, -0.7142,  1.2668,  0.6548],\n",
      "          [-1.6644,  0.3740, -0.7306,  1.7333, -0.1193],\n",
      "          [-2.2103, -1.2614,  1.6621, -1.1264, -0.1207],\n",
      "          [-1.2090,  0.8435, -0.5869,  1.3360, -0.1406],\n",
      "          [ 0.6898, -0.3800,  0.1006, -0.1507, -2.2542]],\n",
      "\n",
      "         [[-1.1414,  0.6013,  0.9045,  1.2278,  0.8713],\n",
      "          [-0.9659, -1.1332, -1.7015, -0.1819,  1.3715],\n",
      "          [-1.0631,  0.3989, -0.5882,  0.7387,  0.9144],\n",
      "          [ 0.1593, -1.2801, -0.3866, -0.8150,  0.8159],\n",
      "          [ 0.3853, -0.8052, -2.4429, -0.4445, -0.4533]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1049, -1.0776, -0.0241,  0.6126, -0.1817],\n",
      "          [ 0.8639,  0.5703,  0.6555,  0.3759,  1.2229],\n",
      "          [ 0.7494,  1.7128,  2.9597,  0.8346, -0.0775],\n",
      "          [ 0.9969, -1.0884,  0.8459,  0.7996, -0.1756],\n",
      "          [-0.9533,  0.4099,  0.2127, -2.3388, -0.3047]],\n",
      "\n",
      "         [[ 0.3425,  0.5163,  1.6168, -0.3430,  0.1545],\n",
      "          [-1.4146,  0.8947, -0.3027, -0.5567, -0.2589],\n",
      "          [-1.1007, -0.8649, -0.0173,  1.2885,  2.4435],\n",
      "          [-1.0255,  0.2195,  0.6033,  1.0459,  0.6339],\n",
      "          [-0.2284, -0.5561, -1.2302,  1.1030, -0.8384]],\n",
      "\n",
      "         [[-0.8179,  0.7653,  1.5493,  0.8959, -0.4683],\n",
      "          [ 2.0818,  0.9305,  0.4365, -0.3474,  1.0477],\n",
      "          [ 1.8526,  0.2845,  1.2425,  0.4735,  0.2250],\n",
      "          [-0.3956,  0.6089,  0.1447,  0.8732,  0.3516],\n",
      "          [ 1.3334, -0.5959, -0.6781,  0.3629, -1.4133]]],\n",
      "\n",
      "\n",
      "        [[[-1.6554, -1.3823, -0.6677,  0.3220,  0.4421],\n",
      "          [-0.2244,  1.7116, -0.1716, -1.2611,  0.4139],\n",
      "          [-0.7778,  0.8236,  0.7594, -1.1908,  0.7992],\n",
      "          [ 0.2675,  1.9924, -1.5010,  0.5726,  0.9803],\n",
      "          [ 0.6596,  0.4059, -0.1180,  0.2423,  0.4105]],\n",
      "\n",
      "         [[-1.1309,  0.0509,  0.6738,  0.5577, -2.3386],\n",
      "          [-1.3224, -0.7181, -0.6172, -0.4901,  2.0168],\n",
      "          [-0.9911,  1.9498, -0.4045,  0.3048, -0.7463],\n",
      "          [-0.0995, -0.2869, -0.1024, -0.6153, -0.3163],\n",
      "          [ 1.7024, -1.1254,  0.4206, -0.1255,  0.0136]],\n",
      "\n",
      "         [[ 1.7447,  1.4098,  0.6084, -0.5819,  2.4995],\n",
      "          [ 1.3326,  0.2879,  0.1417, -0.8194,  0.5513],\n",
      "          [ 0.3636,  1.0320,  1.0793, -0.4207, -1.8064],\n",
      "          [-0.5950,  0.8054, -0.1640, -0.0507, -0.8323],\n",
      "          [-1.4269, -0.8066,  0.5346, -0.9576,  1.0955]]],\n",
      "\n",
      "\n",
      "        [[[-1.6485, -0.1273,  0.8950,  0.0122,  0.4928],\n",
      "          [ 1.0103, -0.3329, -1.3935,  0.1231, -0.5398],\n",
      "          [-1.8414,  1.3861, -1.3689, -0.6325,  0.3887],\n",
      "          [-1.0202,  1.1198, -1.3917,  0.5988, -1.0646],\n",
      "          [-1.2089,  1.6686, -0.9950, -0.2143, -0.1994]],\n",
      "\n",
      "         [[-0.6623, -0.4128,  0.0221,  0.4875,  1.4487],\n",
      "          [-0.5649,  1.5184,  0.4381,  0.1421,  0.2984],\n",
      "          [ 0.4321, -1.1183,  0.9865, -0.5602, -0.2311],\n",
      "          [ 1.4007, -1.2109,  1.4777, -1.3853,  1.3698],\n",
      "          [-0.9262,  1.3712, -0.6237,  0.1534,  0.9512]],\n",
      "\n",
      "         [[-0.6964, -1.2240, -0.7139, -1.3957, -0.0157],\n",
      "          [ 1.0603, -0.2292,  0.6216, -1.1137,  0.3789],\n",
      "          [-0.1703,  1.4448, -2.0000,  0.4514, -0.7642],\n",
      "          [-1.3736, -1.2269, -1.0131, -1.1992, -0.8947],\n",
      "          [-0.1318,  0.4979,  0.0156, -1.7318,  0.6696]]]],\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 创建一个模拟的四维数据 (批次大小=4，通道数=3，图像大小=5x5)\n",
    "input_data = torch.randn(4, 3, 5, 5)  # N=4, C=3, H=5, W=5\n",
    "\n",
    "# 定义一个 BatchNorm2d 层，适用于3个通道\n",
    "bn = nn.BatchNorm2d(num_features=3)\n",
    "\n",
    "# 打印输入数据形状\n",
    "print(\"Input shape:\", input_data.shape)\n",
    "\n",
    "# 应用批量归一化\n",
    "output = bn(input_data)\n",
    "\n",
    "# 打印归一化后的输出\n",
    "print(\"Output after Batch Normalization:\")\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout一般放在激活函数之后，用于随机丢弃部分激活值以防止过拟合；而Batch Normalization通常放在线性层或卷积层之后、激活函数之前，用于规范化层输出以加快训练并稳定收敛。常见的顺序是：线性/卷积层 → 批量归一化 → 激活函数 → Dropout。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
